# GraphRAG 构建流程概览

以下流程假定本地环境与基础语料已准备完毕，并以本仓库提供的脚本/配置为起点。若使用自定义工具，可根据同样的阶段性目标调整。

## 1. 语料整备与元数据
- **整理输入源**：按主题、来源、时间段建立文件夹或标注，以便后续筛选。
- **元数据收集**：为每份文档记录标题、作者、日期、文档类型、关键标签等字段，可写入 `data/metadata.csv` 或 JSON 文件。
- **清洗与格式统一**：
  - 去除重复、乱码和无关信息。
  - 将 PDF/图片 OCR 成统一的 UTF-8 文本。
  - 保留段落结构、标题层级与列表标记，为切分提供结构线索。

## 2. 语料切分（Chunking）
- **目的**：便于向量化与关系抽取，保持语义完整。
- **策略建议**：
  - 基于段落/标题优先，其次采用滑动窗口（如 200–400 中文字，重叠 50–100）。
  - 对话或表格类内容可按回合/行切分，确保意图完整。
- **工具**：
  - 使用仓库中的 `scripts/chunk_text.py`（若未创建，可参考 `docs/embeddings.md` 中的示例）或 HuggingFace `textsplit` 等库。
  - 输出格式示例：每个 chunk 包含 `id`、`text`、`source_doc`、`start_idx`、`end_idx`、`metadata`。
- **验证**：抽样检查 chunk 是否保持上下文可读，并记录数量与平均长度。

## 3. 嵌入构建（向量索引）
- **模型选择**：参考 `docs/embeddings.md`，选定适配中文的 Sentence Transformer 或 OpenAI Embeddings。
- **批处理生成**：使用 `scripts/build_embeddings.py`（可按需编写）对 chunk 文本生成向量，保存为 parquet/FAISS。
- **索引管理**：
  - 向量库（FAISS/Chroma）存放于 `data/index/`。
  - 记录模型名称、版本、参数以便复现。

## 4. 关系抽取与知识图谱构建
- **目标**：从 chunk/原文提取实体、概念及其关系。
- **步骤**：
  1. **实体识别**：通过 LLM 提示或信息抽取模型获取人物、地点、概念等。
  2. **关系抽取**：针对实体对生成关系三元组（subject, predicate, object）。
  3. **归并与清洗**：对同义词、别名进行合并，剔除置信度低的关系。
- **实现方式**：
  - 参考 `docs/llm.md`，使用提示模板批量处理 chunk。
  - 将输出写入 `data/graph/nodes.csv` 与 `data/graph/edges.csv`，字段包括 `id`、`label`、`type`、`source`、`confidence`。
- **质量检查**：
  - 人工抽样验证关系准确度。
  - 使用脚本统计实体/关系度分布，排查孤立节点。

## 5. 图索引与检索增强
- **图数据库**：可选 Neo4j、NetworkX 或轻量 JSON Graph。
- **查询层**：构建基于关键词+图遍历的组合检索：
  - 先通过向量搜索锁定候选节点或原始 chunk。
  - 再利用图关系扩展上下文，形成 RAG 的扩展上下文包。
- **缓存与更新**：定期同步向量库与图谱，记录更新时间戳。

## 6. RAG 推理链路整合
- **提示模板**：在 `docs/services.md` 的 API/服务结构基础上，设计 prompt 以同时引用向量检索结果和图谱推理路径。
- **响应结构**：返回答案、证据 chunk、关联节点与关系说明。
- **监测与评估**：
  - 建立问答测试集，评估准确率、召回率。
  - 记录调用日志与延迟，优化批量请求。

## 7. 迭代与运维
- **增量更新**：新增语料后重复 2–4 步，更新图谱与索引。
- **版本管理**：对模型、图谱、索引进行版本标记，方便回退。
- **可视化与分享**：
  - 使用 `scripts/visualize_graph.py`（可自行开发）导出 GraphML 或 web 可视化。
  - 编写使用手册与 FAQ，面向业务团队推广。

## 常见问题解答
- **是否必须先切分语料？** 是的，chunking 是后续向量化和关系抽取的基础。但在结构化数据（如数据库导出）中，可直接以记录为单位。
- **图谱构建与向量检索顺序？** 通常并行进行：切分后即可生成向量；同时，用相同的 chunk 输入 LLM 进行关系抽取。确保两个索引使用一致的 chunk ID 以便交叉引用。
- **如何处理噪声关系？** 设置最低置信度阈值（如 0.5），并结合人工审核或基于规则的过滤。

---

若需要自动化脚本示例，可在 `scripts/` 目录创建对应的 Python 脚本，调用仓库已有的向量化与 LLM 接口。请在实现前确认所需 API 密钥已配置于环境变量。
